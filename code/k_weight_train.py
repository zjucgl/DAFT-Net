import matplotlib
import pandas as pd
import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import time
from torch import nn, optim
from torch.utils.data import DataLoader
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error, accuracy_score, roc_auc_score, f1_score, recall_score, precision_score

from data_processing import preprocess_data
from dataset_weight import MyWeightDataset  # ä½¿ç”¨ MyWeightDataset
from models.twoStage_aft_model import FusionAFTModel
from models.twoStage_mlpmixer_model import FusionMLPMixerModel
from models.twoStage_update_aft_model import FusionAFTUPModel
from models.twoStage_weight_dyt_model import FusionAFTUPDWModel
from models.twoStage_weight_model import FusionAFTUPWModel

# ==================== 1ï¸âƒ£ è¯»å–æ•°æ® ====================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
matplotlib.rc("font", family='WenQuanYi Micro Hei')

# è®­ç»ƒé›†
data = pd.read_csv('data/20240205133204/train.csv')
data = data.applymap(lambda x: x.strip() if isinstance(x, str) else x)  # æ¸…ç†æ•°æ®
data = preprocess_data(data)
dataset = MyWeightDataset(data)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# æµ‹è¯•é›†
test_data = pd.read_csv('data/20240205133204/test.csv')
test_data = test_data.applymap(lambda x: x.strip() if isinstance(x, str) else x)
test_data = preprocess_data(test_data)
test_dataset = MyWeightDataset(test_data)
test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# ==================== 2ï¸âƒ£ äº¤å‰éªŒè¯ ====================
kf = KFold(n_splits=10, shuffle=True, random_state=42)  # è®¾ç½®10æŠ˜äº¤å‰éªŒè¯
best_auc = 0.0
best_model_path = "best_model_auc.pth"
num_epochs = 40  # è®­ç»ƒè½®æ•°

# ç”¨äºè®°å½•æ‰€æœ‰ epoch çš„è®­ç»ƒ loss
epoch_losses = []
total_start_time = time.time()

for fold, (train_idx, val_idx) in enumerate(kf.split(data)):
    print(f"Fold {fold+1}/{kf.get_n_splits()}")

    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_data = data.iloc[train_idx]
    val_data = data.iloc[val_idx]

    # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    train_dataset = MyWeightDataset(train_data)
    val_dataset = MyWeightDataset(val_data)

    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)

    # ==================== 3ï¸âƒ£ åˆå§‹åŒ–æ¨¡å‹ ====================
    # é€‰æ‹©å…¶ä¸­ä¸€ä¸ªæ¨¡å‹ç‰ˆæœ¬è¿›è¡Œè®­ç»ƒï¼ˆæ­¤å¤„ä»¥ FusionAFTUPDWModel ä¸ºä¾‹ï¼‰
    # model = FusionAFTUPWModel(condition_dim=7).to(device)
    model = FusionAFTUPDWModel(condition_dim=7).to(device)  # é‡æ–°åˆå§‹åŒ–æ¨¡å‹

    # æŠ¥é”™ï¼Œå°±è¿™æ ·ï¼Œä½¿ç”¨è¿™ä¸ªæ¨¡å‹è¿›è¡Œè®²æ•…äº‹
    # model = FusionAFTUPDWModel(condition_dim=7).to(device)


    criterion = nn.BCELoss()  # äºŒå…ƒäº¤å‰ç†µæŸå¤±
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # è®°å½•å½“å‰ fold æœ€å¥½çš„ AUC
    best_fold_auc = 0.0

    # ==================== 4ï¸âƒ£ è®­ç»ƒå’ŒéªŒè¯ ====================
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        all_train_labels, all_train_preds = [], []

        for batch in train_dataloader:
            (basic_data, blood_data, text_data_encoded, raw_data,
             basic_risk_data_encoded, blood_risk_data_encoded, context_input, labels) = batch  # è·å– context_input

            # å‘é€åˆ° GPU
            basic_data, blood_data, text_data_encoded, raw_data, basic_risk_data_encoded, blood_risk_data_encoded, context_input, labels = (
                basic_data.to(device), blood_data.to(device), text_data_encoded.to(device),
                raw_data.to(device), basic_risk_data_encoded.to(device), blood_risk_data_encoded.to(device),
                context_input.to(device), labels.to(device).float()
            )

            optimizer.zero_grad()
            disease_pred, _ = model(basic_data, blood_data, text_data_encoded, raw_data,
                                    basic_risk_data_encoded, blood_risk_data_encoded, context_input)

            loss = criterion(disease_pred.squeeze(), labels)
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

            # è®°å½•è®­ç»ƒé›†çœŸå®å€¼å’Œé¢„æµ‹å€¼
            all_train_labels.extend(labels.cpu().numpy())
            all_train_preds.extend(disease_pred.squeeze().cpu().detach().numpy())

        avg_loss = total_loss / len(train_dataloader)
        epoch_losses.append(avg_loss)
        train_auc = roc_auc_score(all_train_labels, all_train_preds)

        # ==================== éªŒè¯ ====================
        model.eval()
        all_val_labels, all_val_preds = [], []
        with torch.no_grad():
            for batch in val_dataloader:
                (basic_data, blood_data, text_data_encoded, raw_data,
                 basic_risk_data_encoded, blood_risk_data_encoded, context_input, labels) = batch

                basic_data, blood_data, text_data_encoded, raw_data, basic_risk_data_encoded, blood_risk_data_encoded, context_input = (
                    basic_data.to(device), blood_data.to(device), text_data_encoded.to(device),
                    raw_data.to(device), basic_risk_data_encoded.to(device), blood_risk_data_encoded.to(device),
                    context_input.to(device)
                )

                disease_pred, _ = model(basic_data, blood_data, text_data_encoded, raw_data,
                                        basic_risk_data_encoded, blood_risk_data_encoded, context_input)
                all_val_labels.extend(labels.numpy())
                all_val_preds.extend(disease_pred.squeeze().cpu().numpy())

        val_auc = roc_auc_score(all_val_labels, all_val_preds)
        print(f"Fold {fold+1}, Epoch [{epoch+1}/{num_epochs}]: Train Loss: {avg_loss:.4f}, Train AUC: {train_auc:.4f}, Val AUC: {val_auc:.4f}")

        if val_auc > best_fold_auc and train_auc >= 0.70:  # å¯è®¾å®šè®­ç»ƒé›† AUC é˜ˆå€¼
            best_fold_auc = val_auc
            torch.save(model.state_dict(), best_model_path)
            print(f"ğŸ‰ New best model saved for fold {fold+1} with Val AUC: {best_fold_auc:.4f}")

    # åŠ è½½å½“å‰ fold æœ€å¥½çš„æ¨¡å‹
    model.load_state_dict(torch.load(best_model_path))
    model.eval()
    print(f"âœ… Loaded best model for fold {fold+1} with AUC: {best_fold_auc:.4f}")
    if best_fold_auc > best_auc:
        best_auc = best_fold_auc

total_training_time = time.time() - total_start_time
print(f"ğŸ‰ Final best AUC across all folds: {best_auc:.4f}")
print(f"Total training time: {total_training_time:.2f} seconds")

# ==================== 5ï¸âƒ£ æµ‹è¯•é›†è¯„ä¼° ====================
model.eval()
all_test_labels, all_test_preds = [], []

with torch.no_grad():
    for batch in test_dataloader:
        (basic_data, blood_data, text_data_encoded, raw_data,
         basic_risk_data_encoded, blood_risk_data_encoded, context_input, labels) = batch

        basic_data, blood_data, text_data_encoded, raw_data, basic_risk_data_encoded, blood_risk_data_encoded, context_input = (
            basic_data.to(device), blood_data.to(device), text_data_encoded.to(device),
            raw_data.to(device), basic_risk_data_encoded.to(device), blood_risk_data_encoded.to(device),
            context_input.to(device)
        )

        disease_pred, _ = model(basic_data, blood_data, text_data_encoded, raw_data,
                                basic_risk_data_encoded, blood_risk_data_encoded, context_input)
        all_test_labels.extend(labels.numpy())
        all_test_preds.extend(disease_pred.squeeze().cpu().numpy())

test_auc = roc_auc_score(all_test_labels, all_test_preds)
test_mse = mean_squared_error(all_test_labels, all_test_preds)
test_acc = accuracy_score(all_test_labels, np.round(all_test_preds))
# é‡‡ç”¨ 0.7 é˜ˆå€¼å°†é¢„æµ‹æ¦‚ç‡è½¬æ¢ä¸ºäºŒåˆ†ç±»æ ‡ç­¾
test_predictions = (np.array(all_test_preds) > 0.7).astype(int)
test_labels = np.array(all_test_labels)

# è®¡ç®—å…¶ä»–æŒ‡æ ‡
test_f1 = f1_score(test_labels, test_predictions)
test_recall = recall_score(test_labels, test_predictions)
test_precision = precision_score(test_labels, test_predictions)
rmse = np.sqrt(test_mse)

print(f"Test   - MSE: {test_mse:.4f}, RMSE: {rmse:.4f}, ACC: {test_acc:.4f}, AUC: {test_auc:.4f}, "
      f"F1: {test_f1:.4f}, Recall: {test_recall:.4f}, Precision: {test_precision:.4f}")

# print(f"Test   - MSE: {test_mse:.4f}, ACC: {test_acc:.4f}, AUC: {test_auc:.4f}")

# ==================== 6ï¸âƒ£ ç»˜åˆ¶ Loss æ›²çº¿ ====================
plt.figure(figsize=(8, 6))
plt.plot(range(1, len(epoch_losses)+1), epoch_losses, marker='o', linestyle='-', color='blue')
plt.xlabel("Epoch")
plt.ylabel("Training Loss")
plt.title("Training Loss Curve")
plt.grid(True)
plt.show()
